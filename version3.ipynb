{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "import discogs_client\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from typing import Dict\n",
    "import re\n",
    "import json\n",
    "\n",
    "import discogs_client\n",
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from typing import Dict, List, Tuple, Optional, Set\n",
    "from fuzzywuzzy import fuzz\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spotify Client Credentials\n",
    "CLIENT_ID = \"26c65df3e5844f1dbe355d82d80c9f6f\"\n",
    "CLIENT_SECRET = \"2d4d2b147bc942b999564a5e8649b987\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize SpotiPy with user credentials\n",
    "sp = spotipy.Spotify(auth_manager=SpotifyClientCredentials(client_id=CLIENT_ID,\n",
    "                                                           client_secret=CLIENT_SECRET))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DISCOGS_TOKEN = \"FbbkQDyGoGsJlnSqVfFwqfvUWnrtDcBiWmyHOHjX\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = discogs_client.Client(\n",
    "    'my_user_agent/1.0',\n",
    "    consumer_key='hZZUdNwRHsUxlgReVdCA',\n",
    "    consumer_secret='TUAxCaABSkDcmQgeRhIbRRvnHAopOIkH',\n",
    "    token=u'FbbkQDyGoGsJlnSqVfFwqfvUWnrtDcBiWmyHOHjX',\n",
    "    secret=u'my_token_secret'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('JTfOijPtVyoofoZuCFkMvzZxhwvjqeMPwBiHjcDY',\n",
       " 'FmSOtUMYInQRCcMZkhBmqiLVksoKWLUNzMGXgjPg',\n",
       " 'https://www.discogs.com/oauth/authorize?oauth_token=JTfOijPtVyoofoZuCFkMvzZxhwvjqeMPwBiHjcDY')"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.get_authorize_url()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('VCZoAzRfzvAnLcbzZnndWJySibZBjSbWIkEzPHKs',\n",
       " 'ZOOElKovUzaSKAyoysxesAZgitaBBOrXdlnsHCbq')"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.get_access_token(\"FJwsqclHeX\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<User 2177455 'oliebab'>\n"
     ]
    }
   ],
   "source": [
    "me = d.identity()\n",
    "print(me)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Breaks', 'Techno', 'Abstract', 'Acid', 'IDM']\n"
     ]
    }
   ],
   "source": [
    "release = d.release(30690634).styles\n",
    "print(release)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import discogs_client\n",
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from typing import Dict, List, Tuple, Optional, Set\n",
    "from fuzzywuzzy import fuzz\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class MusicRecommender:\n",
    "    def __init__(self, spotify_client_id: str, spotify_client_secret: str, discogs_token: str):\n",
    "        \"\"\"Initialize the recommender with API credentials.\"\"\"\n",
    "        # Initialize Spotify client\n",
    "        self.spotify = spotipy.Spotify(\n",
    "            client_credentials_manager=SpotifyClientCredentials(\n",
    "                client_id=spotify_client_id,\n",
    "                client_secret=spotify_client_secret\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        # Initialize Discogs client\n",
    "        self.discogs = discogs_client.Client(\n",
    "            'MusicRecommender/1.0',\n",
    "            user_token=discogs_token\n",
    "        )\n",
    "        \n",
    "        # Define audio features for analysis\n",
    "        self.audio_features = [\n",
    "            'danceability', 'energy', 'speechiness',\n",
    "            'acousticness', 'instrumentalness', 'liveness', 'valence'\n",
    "        ]\n",
    "        self.all_features = self.audio_features + ['tempo', 'key', 'mode']\n",
    "        \n",
    "        # Define clustering parameters\n",
    "        self.n_clusters = 8\n",
    "        self.clustering_features = [\n",
    "            'danceability', 'energy', 'speechiness',\n",
    "            'acousticness', 'instrumentalness', 'liveness', 'valence',\n",
    "            'tempo_normalized'\n",
    "        ]\n",
    "        \n",
    "        # Initialize components\n",
    "        self.initialize_musical_keys()\n",
    "        self.initialize_genre_mapping()\n",
    "        \n",
    "        # Load and prepare reference dataset\n",
    "        try:\n",
    "            self.reference_df = pd.read_csv('complete/spotify_complete_data.csv')\n",
    "            print(f\"Successfully loaded dataset with {len(self.reference_df)} tracks\")\n",
    "            \n",
    "            # Process musical features\n",
    "            self.process_musical_features()\n",
    "            # Initialize clustering\n",
    "            self._initialize_clustering()\n",
    "        except FileNotFoundError:\n",
    "            raise FileNotFoundError(\"Could not find spotify_complete_data.csv\")\n",
    "        except Exception as e:\n",
    "            raise Exception(f\"Error processing dataset: {str(e)}\")\n",
    "\n",
    "    def initialize_musical_keys(self):\n",
    "        \"\"\"Initialize musical key mappings and relationships.\"\"\"\n",
    "        # Spotify key notation (Camelot compatible)\n",
    "        self.key_map = {\n",
    "            -1: ['--', 'Unknown'],\n",
    "            0: ['8B', 'C'],\n",
    "            1: ['3B', 'C#/Db'],\n",
    "            2: ['10B', 'D'],\n",
    "            3: ['5B', 'D#/Eb'],\n",
    "            4: ['12B', 'E'],\n",
    "            5: ['7B', 'F'],\n",
    "            6: ['2B', 'F#/Gb'],\n",
    "            7: ['9B', 'G'],\n",
    "            8: ['4B', 'G#/Ab'],\n",
    "            9: ['11B', 'A'],\n",
    "            10: ['6B', 'A#/Bb'],\n",
    "            11: ['1B', 'B']\n",
    "        }\n",
    "        \n",
    "        # Mapping for minor keys\n",
    "        self.key_map_minor = {\n",
    "            -1: ['--', 'Unknown'],\n",
    "            0: ['8A', 'Am'],\n",
    "            1: ['3A', 'A#m/Bbm'],\n",
    "            2: ['10A', 'Bm'],\n",
    "            3: ['5A', 'Cm'],\n",
    "            4: ['12A', 'C#m/Dbm'],\n",
    "            5: ['7A', 'Dm'],\n",
    "            6: ['2A', 'D#m/Ebm'],\n",
    "            7: ['9A', 'Em'],\n",
    "            8: ['4A', 'Fm'],\n",
    "            9: ['11A', 'F#m/Gbm'],\n",
    "            10: ['6A', 'Gm'],\n",
    "            11: ['1A', 'G#m/Abm']\n",
    "        }\n",
    "        \n",
    "        # Key compatibility matrix\n",
    "        self.compatible_keys = {\n",
    "            -1: range(12),\n",
    "            0: [11, 1, 5],\n",
    "            1: [0, 2, 6],\n",
    "            2: [1, 3, 7],\n",
    "            3: [2, 4, 8],\n",
    "            4: [3, 5, 9],\n",
    "            5: [4, 6, 10],\n",
    "            6: [5, 7, 11],\n",
    "            7: [6, 8, 0],\n",
    "            8: [7, 9, 1],\n",
    "            9: [8, 10, 2],\n",
    "            10: [9, 11, 3],\n",
    "            11: [10, 0, 4]\n",
    "        }\n",
    "        \n",
    "        # Energy levels for keys\n",
    "        self.key_energy = {\n",
    "            -1: 0.5,  # Unknown\n",
    "            0: 0.7,   # C\n",
    "            1: 0.8,   # C#/Db\n",
    "            2: 0.6,   # D\n",
    "            3: 0.7,   # D#/Eb\n",
    "            4: 0.8,   # E\n",
    "            5: 0.6,   # F\n",
    "            6: 0.7,   # F#/Gb\n",
    "            7: 0.6,   # G\n",
    "            8: 0.7,   # G#/Ab\n",
    "            9: 0.8,   # A\n",
    "            10: 0.7,  # A#/Bb\n",
    "            11: 0.8   # B\n",
    "        }\n",
    "\n",
    "    def get_full_key(self, key: int, mode: int) -> str:\n",
    "        \"\"\"Get full key name including mode.\"\"\"\n",
    "        if key == -1:\n",
    "            return \"Unknown\"\n",
    "        \n",
    "        if mode == 1:  # Major\n",
    "            return self.key_map[key][1]\n",
    "        else:  # Minor\n",
    "            return self.key_map_minor[key][1]\n",
    "    \n",
    "    def _get_key_group(self, key: int, mode: int) -> str:\n",
    "        \"\"\"Get key group for compatibility matching.\"\"\"\n",
    "        if key == -1:\n",
    "            return \"Unknown\"\n",
    "        \n",
    "        base_key = key if mode == 1 else (key + 3) % 12\n",
    "        if base_key in [0, 5, 7]:  # C, F, G\n",
    "            return \"Primary\"\n",
    "        elif base_key in [2, 9, 4]:  # D, A, E\n",
    "            return \"Secondary\"\n",
    "        else:\n",
    "            return \"Tertiary\"\n",
    "    \n",
    "    def check_key_compatibility(self, key1: int, key2: int, mode1: int = 1, mode2: int = 1) -> float:\n",
    "        \"\"\"Calculate compatibility score between two musical keys.\"\"\"\n",
    "        if key1 == -1 or key2 == -1:\n",
    "            return 0.5\n",
    "        \n",
    "        camelot1 = self.key_map[key1][0] if mode1 == 1 else self.key_map_minor[key1][0]\n",
    "        camelot2 = self.key_map[key2][0] if mode2 == 1 else self.key_map_minor[key2][0]\n",
    "        \n",
    "        if camelot1 == camelot2:\n",
    "            return 1.0\n",
    "        \n",
    "        if key2 in self.compatible_keys[key1]:\n",
    "            return 0.8 if mode1 == mode2 else 0.7\n",
    "        \n",
    "        steps = min((key1 - key2) % 12, (key2 - key1) % 12)\n",
    "        base_score = max(0.2, 1 - (steps * 0.1))\n",
    "        \n",
    "        return base_score * 0.9 if mode1 != mode2 else base_score\n",
    "    \n",
    "    def _normalize_bpm(self, bpm: float) -> float:\n",
    "        \"\"\"Normalize BPM to standard range.\"\"\"\n",
    "        try:\n",
    "            if pd.isna(bpm) or bpm <= 0:\n",
    "                return -1\n",
    "            \n",
    "            bpm = float(bpm)\n",
    "            while bpm < 80:\n",
    "                bpm *= 2\n",
    "            while bpm > 160:\n",
    "                bpm /= 2\n",
    "            \n",
    "            return bpm\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error normalizing BPM {bpm}: {str(e)}\")\n",
    "            return -1\n",
    "\n",
    "    def analyze_bpm_compatibility(self, bpm1: float, bpm2: float) -> float:\n",
    "        \"\"\"Calculate BPM compatibility score between two tracks.\"\"\"\n",
    "        try:\n",
    "            if pd.isna(bpm1) or pd.isna(bpm2) or bpm1 <= 0 or bpm2 <= 0:\n",
    "                return 0.5  # Default compatibility for invalid BPMs\n",
    "            \n",
    "            # Normalize both BPMs\n",
    "            bpm1_norm = self._normalize_bpm(float(bpm1))\n",
    "            bpm2_norm = self._normalize_bpm(float(bpm2))\n",
    "            \n",
    "            # Calculate absolute difference\n",
    "            diff = abs(bpm1_norm - bpm2_norm)\n",
    "            \n",
    "            # Score based on difference\n",
    "            if diff <= 2:\n",
    "                return 1.0    # Perfect match\n",
    "            elif diff <= 4:\n",
    "                return 0.9    # Very good match\n",
    "            elif diff <= 6:\n",
    "                return 0.8    # Good match\n",
    "            elif diff <= 8:\n",
    "                return 0.7    # Decent match\n",
    "            elif diff <= 10:\n",
    "                return 0.6    # Acceptable match\n",
    "            else:\n",
    "                # Decreasing compatibility for larger differences\n",
    "                return max(0.2, 1 - (diff * 0.05))\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error in BPM compatibility analysis: {str(e)}\")\n",
    "            return 0.5  # Default compatibility score on error\n",
    "\n",
    "    def get_bpm_range_for_genre(self, genre: str) -> Tuple[float, float]:\n",
    "        \"\"\"Get typical BPM range for a given genre.\"\"\"\n",
    "        # Typical BPM ranges for electronic music genres\n",
    "        bpm_ranges = {\n",
    "            'techno': (120, 140),\n",
    "            'house': (120, 130),\n",
    "            'drum and bass': (160, 180),\n",
    "            'dubstep': (140, 150),\n",
    "            'trance': (130, 145),\n",
    "            'ambient': (60, 120),\n",
    "            'downtempo': (80, 110),\n",
    "            'breakbeat': (120, 150),\n",
    "            'electro': (120, 135),\n",
    "            'minimal': (125, 130),\n",
    "            'dub': (130, 150),\n",
    "            'experimental': (0, 200),  # Wide range for experimental\n",
    "            'idm': (80, 160)          # Wide range for IDM\n",
    "        }\n",
    "        \n",
    "        # Normalize genre string\n",
    "        genre = genre.lower().strip()\n",
    "        \n",
    "        # Return the BPM range if found, otherwise return a default range\n",
    "        return bpm_ranges.get(genre, (100, 140))  # Default range if genre not found\n",
    "\n",
    "    def process_musical_features(self):\n",
    "        \"\"\"Process and normalize musical features in reference dataset.\"\"\"\n",
    "        try:\n",
    "            # Process tempo/BPM\n",
    "            if 'tempo' in self.reference_df.columns:\n",
    "                self.reference_df['tempo'] = self.reference_df['tempo'].fillna(-1)\n",
    "                # Add normalized tempo column\n",
    "                self.reference_df['tempo_normalized'] = self.reference_df['tempo'].apply(\n",
    "                    lambda x: x if x == -1 else (\n",
    "                        x/2 if x > 160 else (x*2 if x < 80 else x)\n",
    "                    )\n",
    "                )\n",
    "            else:\n",
    "                self.reference_df['tempo'] = -1\n",
    "                self.reference_df['tempo_normalized'] = -1\n",
    "\n",
    "            # Process key information\n",
    "            if 'key' in self.reference_df.columns:\n",
    "                self.reference_df['key'] = self.reference_df['key'].fillna(-1).astype(int)\n",
    "            else:\n",
    "                self.reference_df['key'] = -1\n",
    "\n",
    "            if 'mode' in self.reference_df.columns:\n",
    "                self.reference_df['mode'] = self.reference_df['mode'].fillna(1).astype(int)\n",
    "            else:\n",
    "                self.reference_df['mode'] = 1\n",
    "\n",
    "            # Create full key representation\n",
    "            self.reference_df['key_full'] = self.reference_df.apply(\n",
    "                lambda row: self.get_full_key(row['key'], row['mode']),\n",
    "                axis=1\n",
    "            )\n",
    "\n",
    "            # Create key compatibility groups\n",
    "            self.reference_df['key_group'] = self.reference_df.apply(\n",
    "                lambda row: self._get_key_group(row['key'], row['mode']),\n",
    "                axis=1\n",
    "            )\n",
    "\n",
    "            # Normalize all features for clustering\n",
    "            features_to_normalize = [\n",
    "                'danceability', 'energy', 'speechiness',\n",
    "                'acousticness', 'instrumentalness', 'liveness', 'valence'\n",
    "            ]\n",
    "            \n",
    "            # Ensure all required features exist\n",
    "            for feature in features_to_normalize:\n",
    "                if feature not in self.reference_df.columns:\n",
    "                    self.reference_df[feature] = 0\n",
    "            \n",
    "            # Create tempo_normalized if not already present\n",
    "            if 'tempo_normalized' not in self.reference_df.columns:\n",
    "                self.reference_df['tempo_normalized'] = self.reference_df['tempo'].apply(\n",
    "                    lambda x: x if x == -1 else (\n",
    "                        x/2 if x > 160 else (x*2 if x < 80 else x)\n",
    "                    )\n",
    "                )\n",
    "            \n",
    "            print(\"Available features after processing:\", self.reference_df.columns.tolist())\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error in process_musical_features: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def initialize_genre_mapping(self):\n",
    "        \"\"\"Initialize comprehensive mappings between Discogs styles and electronic music genres.\"\"\"\n",
    "        self.style_mappings = {\n",
    "            # Techno and related styles\n",
    "            'techno': [\n",
    "                'techno', 'detroit techno', 'minimal techno', 'acid techno', \n",
    "                'industrial techno', 'dub techno', 'hard techno', 'experimental techno',\n",
    "                'tech house', 'minimal', 'loops & samples', 'tribal', 'warehouse techno',\n",
    "                'peak time techno', 'hypnotic techno', 'raw techno', 'atmospheric techno',\n",
    "                'melodic techno', 'broken techno', 'techno industrial'\n",
    "            ],\n",
    "            \n",
    "            # House and related styles\n",
    "            'house': [\n",
    "                'house', 'deep house', 'tech house', 'acid house', 'minimal house',\n",
    "                'progressive house', 'tribal house', 'disco house', 'funky house',\n",
    "                'chicago house', 'microhouse', 'electro house', 'minimal/tech house',\n",
    "                'soulful house', 'vocal house', 'garage house', 'filter house',\n",
    "                'melodic house', 'jackin house', 'raw house', 'ghetto house'\n",
    "            ],\n",
    "            \n",
    "            # Ambient and atmospheric\n",
    "            'ambient': [\n",
    "                'ambient', 'dark ambient', 'atmospheric', 'drone', 'soundscape',\n",
    "                'experimental ambient', 'space ambient', 'ambient techno', \n",
    "                'ambient dub', 'downtempo', 'chill out', 'isolationist',\n",
    "                'fourth world', 'environmental', 'ethereal', 'cinematic ambient',\n",
    "                'cosmic', 'abstract ambient', 'ambient industrial'\n",
    "            ],\n",
    "            \n",
    "            # Drum and Bass / Jungle\n",
    "            'drum and bass': [\n",
    "                'drum and bass', 'dnb', 'jungle', 'atmospheric dnb', 'darkstep',\n",
    "                'neurofunk', 'jump up', 'liquid funk', 'breakcore', 'intelligent dnb',\n",
    "                'techstep', 'hardstep', 'drumfunk', 'ragga jungle', 'crossbreed',\n",
    "                'minimal dnb', 'deep dnb', 'dark dnb', 'roller', 'half time'\n",
    "            ],\n",
    "            \n",
    "            # Dub and related\n",
    "            'dub': [\n",
    "                'dub', 'dub techno', 'deep dub', 'ambient dub', 'dubstep',\n",
    "                'dub house', 'reggae', 'minimal dub', 'tech dub',\n",
    "                'dub ambient', 'abstract dub', 'dubbed out', 'steppers',\n",
    "                'roots', 'digi dub', 'uk dub', 'space dub'\n",
    "            ],\n",
    "            \n",
    "            # IDM and Experimental\n",
    "            'idm': [\n",
    "                'idm', 'braindance', 'experimental', 'glitch', 'microsound',\n",
    "                'algorithmic', 'generative', 'sound art', 'avant-garde',\n",
    "                'musique concrète', 'electroacoustic', 'computer music',\n",
    "                'granular synthesis', 'field recording', 'modular'\n",
    "            ],\n",
    "            \n",
    "            # Breakbeat and Related\n",
    "            'breakbeat': [\n",
    "                'breakbeat', 'breaks', 'nu breaks', 'progressive breaks',\n",
    "                'electro breaks', 'acid breaks', 'breakcore', 'big beat',\n",
    "                'florida breaks', 'nu skool breaks', 'chemical breaks',\n",
    "                'funky breaks', 'tech breaks'\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        # Additional style characteristics\n",
    "        self.style_characteristics = {\n",
    "            'deep': ['deep house', 'deep techno', 'deep dub', 'deep minimal', 'deep dnb'],\n",
    "            'progressive': ['progressive house', 'progressive trance', 'progressive breaks'],\n",
    "            'tribal': ['tribal house', 'tribal techno', 'tribal ambient'],\n",
    "            'dark': ['dark ambient', 'darkstep', 'dark techno', 'dark progressive'],\n",
    "            'hypnotic': ['hypnotic techno', 'hypnotic minimal', 'hypnotic dub'],\n",
    "            'atmospheric': ['atmospheric dnb', 'atmospheric techno', 'atmospheric ambient'],\n",
    "            'minimal': ['minimal techno', 'minimal house', 'minimal dub', 'minimal dnb'],\n",
    "            'experimental': ['experimental techno', 'experimental house', 'experimental electronic']\n",
    "        }\n",
    "        \n",
    "        # BPM ranges for genres\n",
    "        self.genre_bpm_ranges = {\n",
    "            'techno': (125, 140),\n",
    "            'house': (120, 130),\n",
    "            'drum and bass': (160, 180),\n",
    "            'dubstep': (140, 150),\n",
    "            'ambient': (60, 120),\n",
    "            'downtempo': (80, 110),\n",
    "            'breakbeat': (120, 150),\n",
    "            'idm': (80, 160),\n",
    "            'minimal': (125, 130)\n",
    "        }\n",
    "    \n",
    "    def parse_discogs_url(self, url: str) -> Tuple[str, int]:\n",
    "        \"\"\"Parse Discogs URL to extract release type and ID.\"\"\"\n",
    "        master_pattern = r'/master/(\\d+)'\n",
    "        release_pattern = r'/release/(\\d+)'\n",
    "        \n",
    "        master_match = re.search(master_pattern, url)\n",
    "        if master_match:\n",
    "            return 'master', int(master_match.group(1))\n",
    "            \n",
    "        release_match = re.search(release_pattern, url)\n",
    "        if release_match:\n",
    "            return 'release', int(release_match.group(1))\n",
    "            \n",
    "        raise ValueError(\"Invalid Discogs URL format\")\n",
    "\n",
    "    def get_discogs_info(self, url: str) -> Dict:\n",
    "        \"\"\"Get detailed release information from Discogs.\"\"\"\n",
    "        release_type, release_id = self.parse_discogs_url(url)\n",
    "        \n",
    "        try:\n",
    "            if release_type == 'master':\n",
    "                master = self.discogs.master(release_id)\n",
    "                release = master.main_release\n",
    "            else:\n",
    "                release = self.discogs.release(release_id)\n",
    "            \n",
    "            # Extract basic information\n",
    "            info = {\n",
    "                'artist': release.artists[0].name if release.artists else \"Unknown Artist\",\n",
    "                'album': release.title,\n",
    "                'tracks': [track.title for track in release.tracklist \n",
    "                          if track.title and isinstance(track.title, str)],\n",
    "                'genres': release.genres if hasattr(release, 'genres') else [],\n",
    "                'styles': release.styles if hasattr(release, 'styles') else [],\n",
    "                'year': release.year if hasattr(release, 'year') else None,\n",
    "                'label': release.labels[0].name if release.labels else \"Unknown Label\",\n",
    "                'catalog': release.labels[0].catno if release.labels else \"Unknown\",\n",
    "                'format': release.formats[0]['name'] if release.formats else \"Unknown Format\"\n",
    "            }\n",
    "            \n",
    "            # Clean up artist name\n",
    "            info['artist'] = re.sub(r'\\(\\d+\\)', '', info['artist']).strip()\n",
    "            \n",
    "            # Get price statistics through web scraping\n",
    "            price_stats = self._scrape_price_stats(url)\n",
    "            info.update(price_stats)\n",
    "            \n",
    "            return info\n",
    "            \n",
    "        except Exception as e:\n",
    "            raise Exception(f\"Failed to fetch Discogs release: {str(e)}\")\n",
    "\n",
    "    def _scrape_price_stats(self, url: str) -> Dict:\n",
    "        \"\"\"Scrape price statistics from Discogs webpage using Selenium.\"\"\"\n",
    "        # Set Chrome options (you can enable headless mode if desired)\n",
    "        chrome_options = Options()\n",
    "        #chrome_options.add_argument(\"--headless\")\n",
    "        \n",
    "        # Initialize WebDriver using WebDriver Manager\n",
    "        driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)\n",
    "        \n",
    "        try:\n",
    "            # Load the Discogs release page\n",
    "            driver.get(url)\n",
    "            \n",
    "            # Wait for the \"release-stats\" section to load\n",
    "            WebDriverWait(driver, 10).until(\n",
    "                EC.presence_of_element_located((By.ID, \"release-stats\"))\n",
    "            )\n",
    "            \n",
    "            # Locate the price statistics section\n",
    "            price_section = driver.find_element(By.ID, \"release-stats\")\n",
    "\n",
    "            # Initialize a dictionary to store price data\n",
    "            price_info = {'low': None, 'median': None, 'high': None}\n",
    "\n",
    "            # Locate all <li> elements in the price section containing price stats\n",
    "            li_elements = price_section.find_elements(By.TAG_NAME, \"li\")\n",
    "            \n",
    "            for li in li_elements:\n",
    "                # Each <li> should have two spans: one for the label, one for the value\n",
    "                spans = li.find_elements(By.TAG_NAME, \"span\")\n",
    "                if len(spans) == 2:\n",
    "                    label = spans[0].text.strip().lower()\n",
    "                    value = spans[1].text.strip()\n",
    "\n",
    "                    # Map the label to the appropriate field in price_info\n",
    "                    if 'low' in label:\n",
    "                        price_info['low'] = value\n",
    "                    elif 'median' in label:\n",
    "                        price_info['median'] = value\n",
    "                    elif 'high' in label:\n",
    "                        price_info['high'] = value\n",
    "            \n",
    "            return price_info\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error scraping prices with Selenium: {e}\")\n",
    "            return {'low': None, 'median': None, 'high': None}\n",
    "        \n",
    "        finally:\n",
    "            # Close the Selenium driver\n",
    "            driver.quit()\n",
    "\n",
    "    def visualize_album_features(self, tracks_features: List[Dict]) -> None:\n",
    "        \"\"\"Create visualizations for album audio features and track tempos.\"\"\"\n",
    "        # Define features for spider plot (explicitly exclude loudness)\n",
    "        spider_features = [\n",
    "            'danceability', 'energy', 'speechiness',\n",
    "            'acousticness', 'instrumentalness', 'liveness', 'valence'\n",
    "        ]\n",
    "        \n",
    "        # Calculate mean features for radar plot\n",
    "        mean_features = pd.DataFrame(tracks_features)[spider_features].mean()\n",
    "        \n",
    "        # Normalize values between 0 and 1 for radar plot\n",
    "        scaler = MinMaxScaler()\n",
    "        mean_features_scaled = pd.Series(\n",
    "            scaler.fit_transform(mean_features.values.reshape(-1, 1)).flatten(),\n",
    "            index=mean_features.index\n",
    "        )\n",
    "        \n",
    "        # Create figure with subplots\n",
    "        plt.figure(figsize=(15, 6))\n",
    "        \n",
    "        # Radar plot for audio features\n",
    "        ax1 = plt.subplot(121, projection='polar')\n",
    "        angles = np.linspace(0, 2*np.pi, len(spider_features), endpoint=False)\n",
    "        values = mean_features_scaled.values\n",
    "        values = np.concatenate((values, [values[0]]))  # Complete the polygon\n",
    "        angles = np.concatenate((angles, [angles[0]]))\n",
    "        \n",
    "        ax1.plot(angles, values)\n",
    "        ax1.fill(angles, values, alpha=0.25)\n",
    "        ax1.set_xticks(angles[:-1])\n",
    "        ax1.set_xticklabels(spider_features)\n",
    "        ax1.set_ylim(0, 1)  # Set fixed scale 0-1\n",
    "        ax1.set_title(\"Audio Features Profile\")\n",
    "        \n",
    "        # Track tempos horizontal bar chart\n",
    "        ax2 = plt.subplot(122)\n",
    "        track_data = pd.DataFrame(tracks_features)\n",
    "        \n",
    "        # Sort by tempo for better visualization\n",
    "        track_data = track_data.sort_values('tempo')\n",
    "        \n",
    "        # Create horizontal bar chart\n",
    "        ax2.barh(track_data['name'], track_data['tempo'])\n",
    "        ax2.set_xlabel('Tempo (BPM)')\n",
    "        ax2.set_title('Track Tempos')\n",
    "        \n",
    "        # Adjust layout and display\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    def get_spotify_features(self, artist: str, album: str) -> Optional[Dict]:\n",
    "        \"\"\"Get Spotify audio features and metadata for an album.\"\"\"\n",
    "        try:\n",
    "            # Search for album\n",
    "            query = f\"album:{album} artist:{artist}\"\n",
    "            results = self.spotify.search(q=query, type='album', limit=1)\n",
    "            \n",
    "            if not results['albums']['items']:\n",
    "                return None\n",
    "                \n",
    "            album_id = results['albums']['items'][0]['id']\n",
    "            album_info = self.spotify.album(album_id)\n",
    "            \n",
    "            # Get tracks and their audio features\n",
    "            tracks = self.spotify.album_tracks(album_id)['items']\n",
    "            track_ids = [track['id'] for track in tracks]\n",
    "            audio_features = self.spotify.audio_features(track_ids)\n",
    "            \n",
    "            # Combine track info with audio features\n",
    "            tracks_with_features = []\n",
    "            for track, features in zip(tracks, audio_features):\n",
    "                if features:\n",
    "                    track_info = {\n",
    "                        'name': track['name'],\n",
    "                        'preview_url': track['preview_url'],\n",
    "                        'duration_ms': track['duration_ms'],\n",
    "                        **{k: features[k] for k in self.all_features}\n",
    "                    }\n",
    "                    tracks_with_features.append(track_info)\n",
    "            \n",
    "            return {\n",
    "                'album_image': album_info['images'][0]['url'] if album_info['images'] else None,\n",
    "                'tracks': tracks_with_features\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error getting Spotify features: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def _initialize_clustering(self):\n",
    "        \"\"\"Initialize and fit clustering model on reference dataset.\"\"\"\n",
    "        try:\n",
    "            # Ensure all required features exist\n",
    "            clustering_features = [\n",
    "                'danceability', 'energy', 'speechiness',\n",
    "                'acousticness', 'instrumentalness', 'liveness', \n",
    "                'valence', 'tempo_normalized'\n",
    "            ]\n",
    "            \n",
    "            # Create feature DataFrame for clustering\n",
    "            features_df = self.reference_df[clustering_features].copy()\n",
    "            \n",
    "            # Fill any missing values\n",
    "            features_df = features_df.fillna(features_df.mean())\n",
    "            \n",
    "            # Normalize features\n",
    "            scaler = StandardScaler()\n",
    "            features_scaled = scaler.fit_transform(features_df)\n",
    "            \n",
    "            # Perform PCA for dimensionality reduction\n",
    "            self.pca = PCA(n_components=3)\n",
    "            features_pca = self.pca.fit_transform(features_scaled)\n",
    "            \n",
    "            # Fit KMeans clustering\n",
    "            self.kmeans = KMeans(n_clusters=self.n_clusters, random_state=42)\n",
    "            self.reference_df['cluster'] = self.kmeans.fit_predict(features_scaled)\n",
    "            \n",
    "            # Store transformed features\n",
    "            self.reference_df['pca1'] = features_pca[:, 0]\n",
    "            self.reference_df['pca2'] = features_pca[:, 1]\n",
    "            self.reference_df['pca3'] = features_pca[:, 2]\n",
    "            \n",
    "            print(f\"Initialized clustering with {self.n_clusters} clusters\")\n",
    "            self._analyze_clusters()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error in clustering initialization: {str(e)}\")\n",
    "            raise\n",
    "    \n",
    "    def _analyze_clusters(self):\n",
    "        \"\"\"Analyze characteristics of each cluster.\"\"\"\n",
    "        self.cluster_profiles = {}\n",
    "        \n",
    "        for cluster in range(self.n_clusters):\n",
    "            cluster_data = self.reference_df[self.reference_df['cluster'] == cluster]\n",
    "            \n",
    "            # Calculate mean features for cluster\n",
    "            profile = cluster_data[self.clustering_features].mean()\n",
    "            \n",
    "            # Find dominant characteristics\n",
    "            dominant_features = []\n",
    "            for feature in self.clustering_features:\n",
    "                mean_val = profile[feature]\n",
    "                if abs(mean_val) > 0.5:  # Significant deviation from mean\n",
    "                    direction = \"high\" if mean_val > 0 else \"low\"\n",
    "                    dominant_features.append(f\"{direction} {feature}\")\n",
    "            \n",
    "            self.cluster_profiles[cluster] = {\n",
    "                'features': profile,\n",
    "                'size': len(cluster_data),\n",
    "                'dominant_features': dominant_features\n",
    "            }\n",
    "\n",
    "    def find_similar_tracks(self, tracks_features: List[Dict], input_styles: List[str], \n",
    "                          n_recommendations: int = 5) -> pd.DataFrame:\n",
    "        \"\"\"Find similar tracks using clustering and feature matching.\"\"\"\n",
    "        try:\n",
    "            # Create DataFrame for input tracks and ensure all required features\n",
    "            input_df = pd.DataFrame(tracks_features)\n",
    "            \n",
    "            # Define required features\n",
    "            required_features = [\n",
    "                'danceability', 'energy', 'speechiness',\n",
    "                'acousticness', 'instrumentalness', 'liveness', \n",
    "                'valence', 'tempo', 'key', 'mode'\n",
    "            ]\n",
    "            \n",
    "            # Check and fill missing features\n",
    "            for feature in required_features:\n",
    "                if feature not in input_df.columns:\n",
    "                    print(f\"Warning: Missing feature {feature} in input tracks\")\n",
    "                    input_df[feature] = 0\n",
    "            \n",
    "            # Add normalized tempo\n",
    "            input_df['tempo_normalized'] = input_df['tempo'].apply(\n",
    "                lambda x: self._normalize_bpm(float(x))\n",
    "            )\n",
    "            \n",
    "            # Ensure reference dataset has normalized tempo\n",
    "            if 'tempo_normalized' not in self.reference_df.columns:\n",
    "                self.reference_df['tempo_normalized'] = self.reference_df['tempo'].apply(\n",
    "                    lambda x: self._normalize_bpm(float(x))\n",
    "                )\n",
    "            \n",
    "            # Print available features for debugging\n",
    "            print(\"\\nAvailable features in input:\", input_df.columns.tolist())\n",
    "            print(\"Available features in reference:\", self.reference_df.columns.tolist())\n",
    "            \n",
    "            # Calculate mean features of input tracks\n",
    "            clustering_features = [\n",
    "                'danceability', 'energy', 'speechiness',\n",
    "                'acousticness', 'instrumentalness', 'liveness', \n",
    "                'valence', 'tempo_normalized'\n",
    "            ]\n",
    "            \n",
    "            input_cluster_features = input_df[clustering_features]\n",
    "            input_mean = input_cluster_features.mean().values.reshape(1, -1)\n",
    "            \n",
    "            # Scale features for clustering\n",
    "            scaler = StandardScaler()\n",
    "            input_scaled = scaler.fit_transform(input_cluster_features)\n",
    "            input_cluster = self.kmeans.predict(input_scaled)[0]\n",
    "            \n",
    "            print(f\"\\nInput tracks assigned to Cluster {input_cluster}\")\n",
    "            if input_cluster in self.cluster_profiles:\n",
    "                print(\"Cluster characteristics:\")\n",
    "                for feature in self.cluster_profiles[input_cluster]['dominant_features']:\n",
    "                    print(f\"- {feature}\")\n",
    "            \n",
    "            # Prepare features for similarity calculation\n",
    "            ref_features = self.reference_df[clustering_features].copy()\n",
    "            \n",
    "            # Calculate audio similarities\n",
    "            audio_similarities = cosine_similarity(\n",
    "                input_mean.reshape(1, -1),\n",
    "                ref_features.values\n",
    "            )[0]\n",
    "            \n",
    "            # Create candidates DataFrame\n",
    "            candidates = self.reference_df.copy()\n",
    "            candidates['audio_similarity'] = audio_similarities\n",
    "            candidates['cluster_similarity'] = (candidates['cluster'] == input_cluster).astype(float)\n",
    "            \n",
    "            # Calculate style similarity\n",
    "            candidates['style_similarity'] = 0.5  # Default value\n",
    "            style_columns = ['genre', 'genres', 'styles', 'track_genre']\n",
    "            style_column = next((col for col in style_columns if col in candidates.columns), None)\n",
    "            \n",
    "            if style_column:\n",
    "                print(f\"Using {style_column} for style matching\")\n",
    "                candidates['style_similarity'] = candidates[style_column].apply(\n",
    "                    lambda x: self.calculate_style_similarity(input_styles, str(x))\n",
    "                )\n",
    "            \n",
    "            # Calculate BPM compatibility\n",
    "            candidates['bpm_compatibility'] = candidates['tempo'].apply(\n",
    "                lambda x: self.analyze_bpm_compatibility(input_df['tempo'].mean(), x)\n",
    "            )\n",
    "            \n",
    "            # Calculate key compatibility\n",
    "            candidates['key_compatibility'] = candidates.apply(\n",
    "                lambda x: self.check_key_compatibility(\n",
    "                    input_df['key'].mode()[0], \n",
    "                    x['key'],\n",
    "                    input_df['mode'].mode()[0], \n",
    "                    x['mode']\n",
    "                ),\n",
    "                axis=1\n",
    "            )\n",
    "            \n",
    "            # Calculate final score\n",
    "            candidates['final_score'] = (\n",
    "                candidates['style_similarity'] * 0.35 +\n",
    "                candidates['audio_similarity'] * 0.25 +\n",
    "                candidates['cluster_similarity'] * 0.15 +\n",
    "                candidates['bpm_compatibility'] * 0.15 +\n",
    "                candidates['key_compatibility'] * 0.10\n",
    "            )\n",
    "            \n",
    "            # Remove near-duplicates\n",
    "            candidates = candidates[candidates['audio_similarity'] < 0.99]\n",
    "            \n",
    "            # Get diverse recommendations\n",
    "            recommendations = self._get_diverse_recommendations(\n",
    "                candidates, \n",
    "                n_recommendations, \n",
    "                input_styles,\n",
    "                input_df['tempo'].mean(), \n",
    "                input_df['key'].mode()[0]\n",
    "            )\n",
    "            \n",
    "            # Add recommendation reasons\n",
    "            recommendations['recommendation_reason'] = recommendations.apply(\n",
    "                lambda x: self._generate_recommendation_reason(\n",
    "                    x, \n",
    "                    input_styles,\n",
    "                    input_df['tempo'].mean(),\n",
    "                    input_df['key'].mode()[0]\n",
    "                ),\n",
    "                axis=1\n",
    "            )\n",
    "            \n",
    "            print(\"\\nRecommendation Summary:\")\n",
    "            print(f\"Found {len(recommendations)} tracks\")\n",
    "            print(f\"Average similarity score: {recommendations['final_score'].mean():.2f}\")\n",
    "            \n",
    "            return recommendations\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error in find_similar_tracks: {str(e)}\")\n",
    "            print(\"Debug information:\")\n",
    "            print(\"Input features shape:\", input_df.shape if 'input_df' in locals() else \"Not created\")\n",
    "            print(\"Required features:\", required_features)\n",
    "            print(\"Available features:\", input_df.columns.tolist() if 'input_df' in locals() else \"None\")\n",
    "            raise\n",
    "\n",
    "    def analyze_album(self, discogs_url: str) -> Dict:\n",
    "        \"\"\"Main analysis function with clustering and detailed feature analysis.\"\"\"\n",
    "        print(\"Fetching Discogs information...\")\n",
    "        try:\n",
    "            discogs_info = self.get_discogs_info(discogs_url)\n",
    "        except Exception as e:\n",
    "            raise Exception(f\"Error fetching Discogs information: {str(e)}\")\n",
    "        \n",
    "        print(\"Fetching Spotify features...\")\n",
    "        try:\n",
    "            spotify_info = self.get_spotify_features(discogs_info['artist'], discogs_info['album'])\n",
    "            if not spotify_info:\n",
    "                raise ValueError(\"Could not find album on Spotify\")\n",
    "        except Exception as e:\n",
    "            raise Exception(f\"Error fetching Spotify features: {str(e)}\")\n",
    "        \n",
    "        print(\"\\nAlbum Details:\")\n",
    "        print(f\"Artist: {discogs_info['artist']}\")\n",
    "        print(f\"Album: {discogs_info['album']}\")\n",
    "        print(f\"Label: {discogs_info['label']}\")\n",
    "        print(f\"Catalog: {discogs_info['catalog']}\")\n",
    "        print(f\"Format: {discogs_info['format']}\")\n",
    "        print(f\"Year: {discogs_info['year']}\")\n",
    "        print(f\"Styles: {', '.join(discogs_info['styles'])}\")\n",
    "        print(f\"Number of tracks: {len(spotify_info['tracks'])}\")\n",
    "        \n",
    "        # Display price information\n",
    "        print(\"\\nMarket Prices:\")\n",
    "        prices = {k: v for k, v in discogs_info.items() if k in ['low', 'median', 'high']}\n",
    "        if not any(prices.values()) or all(v in [None, 'N/A'] for v in prices.values()):\n",
    "            print(\"No price information available\")\n",
    "        else:\n",
    "            for key, value in prices.items():\n",
    "                if value and value != 'N/A':\n",
    "                    print(f\"{key.capitalize()}: {value}\")\n",
    "        \n",
    "        print(\"\\nGenerating visualizations...\")\n",
    "        try:\n",
    "            plt.close('all')  # Close any existing plots\n",
    "            self.visualize_album_features(spotify_info['tracks'])\n",
    "            plt.show()  # Explicitly show the plots\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Could not create visualizations: {str(e)}\")\n",
    "        \n",
    "        print(\"\\nPerforming musical analysis...\")\n",
    "        try:\n",
    "            # Create DataFrame from tracks and add normalized tempo\n",
    "            track_features = pd.DataFrame(spotify_info['tracks'])\n",
    "            track_features['tempo_normalized'] = track_features['tempo'].apply(\n",
    "                lambda x: self._normalize_bpm(float(x))\n",
    "            )\n",
    "            \n",
    "            # Basic musical features\n",
    "            mean_bpm = track_features['tempo'].mean()\n",
    "            most_common_key = track_features['key'].mode()[0]\n",
    "            most_common_mode = track_features['mode'].mode()[0]\n",
    "            key_name = self.get_full_key(most_common_key, most_common_mode)\n",
    "            \n",
    "            print(f\"Average BPM: {mean_bpm:.1f}\")\n",
    "            print(f\"Predominant Key: {key_name}\")\n",
    "            \n",
    "            # Prepare features for clustering\n",
    "            cluster_features = track_features[self.clustering_features].copy()\n",
    "            # Fill any missing values with means\n",
    "            cluster_features = cluster_features.fillna(cluster_features.mean())\n",
    "            \n",
    "            # Scale features and get cluster\n",
    "            cluster_scaled = StandardScaler().fit_transform(cluster_features)\n",
    "            main_cluster = self.kmeans.predict(cluster_scaled)[0]\n",
    "            \n",
    "            print(f\"\\nCluster Analysis:\")\n",
    "            print(f\"Primary Cluster: {main_cluster}\")\n",
    "            if main_cluster in self.cluster_profiles:\n",
    "                print(\"\\nCluster Characteristics:\")\n",
    "                for feature in self.cluster_profiles[main_cluster]['dominant_features']:\n",
    "                    print(f\"- {feature}\")\n",
    "            \n",
    "            # Print audio feature averages\n",
    "            print(\"\\nAudio Feature Averages:\")\n",
    "            for feature in self.audio_features:\n",
    "                if feature in track_features:\n",
    "                    print(f\"{feature.capitalize()}: {track_features[feature].mean():.3f}\")\n",
    "            \n",
    "            print(\"\\nFinding similar tracks...\")\n",
    "            recommendations = self.find_similar_tracks(\n",
    "                spotify_info['tracks'],\n",
    "                discogs_info['styles']\n",
    "            )\n",
    "            \n",
    "            print(\"\\nRecommendations:\")\n",
    "            for i, track in enumerate(recommendations.to_dict('records'), 1):\n",
    "                print(f\"\\n{i}. {track['track_title']} by {track['artist_name']}\")\n",
    "                print(f\"   Style Match: {track.get('style_similarity', 'N/A'):.2f}\")\n",
    "                print(f\"   Audio Similarity: {track['audio_similarity']:.2f}\")\n",
    "                print(f\"   Overall Score: {track['final_score']:.2f}\")\n",
    "                print(f\"   Reason: {track['recommendation_reason']}\")\n",
    "            \n",
    "            return {\n",
    "                'discogs_info': discogs_info,\n",
    "                'spotify_info': spotify_info,\n",
    "                'recommendations': recommendations.to_dict('records'),\n",
    "                'analysis': {\n",
    "                    'mean_bpm': mean_bpm,\n",
    "                    'key': key_name,\n",
    "                    'cluster': main_cluster,\n",
    "                    'audio_features': track_features[self.audio_features].mean().to_dict()\n",
    "                }\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(\"\\nDebug Information:\")\n",
    "            print(\"Available features:\", track_features.columns.tolist() if 'track_features' in locals() else \"No features\")\n",
    "            print(\"Required features:\", self.clustering_features)\n",
    "            print(\"Error details:\", str(e))\n",
    "            raise Exception(f\"Error in analysis: {str(e)}\")\n",
    "    \n",
    "    def _get_diverse_recommendations(self, candidates: pd.DataFrame, n_recommendations: int, input_styles: List[str], input_bpm: float, input_key: int) -> pd.DataFrame:\n",
    "        \"\"\"Get diverse recommendations ensuring artist variety.\"\"\"\n",
    "        recommendations = []\n",
    "        seen_artists = set()\n",
    "        \n",
    "        # Higher threshold for electronic music\n",
    "        score_threshold = 0.5\n",
    "        qualified_tracks = candidates[candidates['final_score'] > score_threshold]\n",
    "        \n",
    "        if len(qualified_tracks) < n_recommendations:\n",
    "            qualified_tracks = candidates\n",
    "        \n",
    "        for _, track in qualified_tracks.sort_values('final_score', ascending=False).iterrows():\n",
    "            if track['artist_name'] not in seen_artists:\n",
    "                recommendations.append(track)\n",
    "                seen_artists.add(track['artist_name'])\n",
    "                \n",
    "                if len(recommendations) >= n_recommendations:\n",
    "                    break\n",
    "        \n",
    "        recommendations_df = pd.DataFrame(recommendations)\n",
    "        recommendations_df['recommendation_reason'] = recommendations_df.apply(\n",
    "            lambda x: self._generate_recommendation_reason(x, input_styles, input_bpm, input_key),\n",
    "            axis=1\n",
    "        )\n",
    "        \n",
    "        return recommendations_df\n",
    "\n",
    "\n",
    "    def _generate_recommendation_reason(self, track: pd.Series, input_styles: List[str], \n",
    "                                    input_bpm: float, input_key: int) -> str:\n",
    "        \"\"\"Generate detailed explanation for recommendation.\"\"\"\n",
    "        reasons = []\n",
    "\n",
    "        # Style match (if available)\n",
    "        if 'style_similarity' in track:\n",
    "            if track['style_similarity'] > 0.8:\n",
    "                reasons.append(\"Very close style match\")\n",
    "            elif track['style_similarity'] > 0.6:\n",
    "                reasons.append(\"Similar style\")\n",
    "\n",
    "        # BPM compatibility\n",
    "        bpm_diff = abs(track['tempo'] - input_bpm)\n",
    "        if bpm_diff <= 2:\n",
    "            reasons.append(\"Perfect tempo match\")\n",
    "        elif bpm_diff <= 5:\n",
    "            reasons.append(\"Compatible tempo\")\n",
    "\n",
    "        # Key compatibility\n",
    "        if track['key_compatibility'] > 0.8:\n",
    "            reasons.append(\"Harmonically compatible\")\n",
    "\n",
    "        # Audio profile match\n",
    "        if track['audio_similarity'] > 0.8:\n",
    "            reasons.append(\"Very similar sound profile\")\n",
    "        elif track['audio_similarity'] > 0.6:\n",
    "            reasons.append(\"Similar sound characteristics\")\n",
    "\n",
    "        # Add specific feature matches if notable\n",
    "        feature_highlights = []\n",
    "        for feature in ['energy', 'danceability', 'instrumentalness']:\n",
    "            if feature in track and track[feature] > 0.7:\n",
    "                feature_highlights.append(f\"high {feature}\")\n",
    "            elif feature in track and track[feature] < 0.3:\n",
    "                feature_highlights.append(f\"low {feature}\")\n",
    "\n",
    "        if feature_highlights:\n",
    "            reasons.append(f\"Matching {', '.join(feature_highlights)}\")\n",
    "\n",
    "        return \"; \".join(reasons) if reasons else \"General style and audio match\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Example usage\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m----> 3\u001b[0m     recommender \u001b[38;5;241m=\u001b[39m MusicRecommender(\n\u001b[0;32m      4\u001b[0m         spotify_client_id\u001b[38;5;241m=\u001b[39mCLIENT_ID,\n\u001b[0;32m      5\u001b[0m         spotify_client_secret\u001b[38;5;241m=\u001b[39mCLIENT_SECRET,\n\u001b[0;32m      6\u001b[0m         discogs_token\u001b[38;5;241m=\u001b[39mDISCOGS_TOKEN\n\u001b[0;32m      7\u001b[0m     )\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;66;03m# Analyze an album\u001b[39;00m\n\u001b[0;32m     10\u001b[0m     url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://www.discogs.com/release/2619151-Sandwell-District-Feed-Forward\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "Cell \u001b[1;32mIn[25], line 58\u001b[0m, in \u001b[0;36mMusicRecommender.__init__\u001b[1;34m(self, spotify_client_id, spotify_client_secret, discogs_token)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# Load and prepare reference dataset\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 58\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreference_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcomplete/spotify_complete_data.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSuccessfully loaded dataset with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreference_df)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m tracks\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;66;03m# Process musical features\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\olivi\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mc:\\Users\\olivi\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:626\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[0;32m    625\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[1;32m--> 626\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\u001b[38;5;241m.\u001b[39mread(nrows)\n",
      "File \u001b[1;32mc:\\Users\\olivi\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1923\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1916\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[0;32m   1917\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1918\u001b[0m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[0;32m   1919\u001b[0m     (\n\u001b[0;32m   1920\u001b[0m         index,\n\u001b[0;32m   1921\u001b[0m         columns,\n\u001b[0;32m   1922\u001b[0m         col_dict,\n\u001b[1;32m-> 1923\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mread(  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m   1924\u001b[0m         nrows\n\u001b[0;32m   1925\u001b[0m     )\n\u001b[0;32m   1926\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1927\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\Users\\olivi\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:234\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlow_memory:\n\u001b[1;32m--> 234\u001b[0m         chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader\u001b[38;5;241m.\u001b[39mread_low_memory(nrows)\n\u001b[0;32m    235\u001b[0m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[0;32m    236\u001b[0m         data \u001b[38;5;241m=\u001b[39m _concatenate_chunks(chunks)\n",
      "File \u001b[1;32mparsers.pyx:838\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:905\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:874\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:891\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:2053\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m<frozen codecs>:331\u001b[0m, in \u001b[0;36mgetstate\u001b[1;34m(self)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    recommender = MusicRecommender(\n",
    "        spotify_client_id=CLIENT_ID,\n",
    "        spotify_client_secret=CLIENT_SECRET,\n",
    "        discogs_token=DISCOGS_TOKEN\n",
    "    )\n",
    "    \n",
    "    # Analyze an album\n",
    "    url = \"https://www.discogs.com/release/2619151-Sandwell-District-Feed-Forward\"\n",
    "    results = recommender.analyze_album(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not open requirements file: [Errno 2] No such file or directory: 'rapidsai'\n"
     ]
    }
   ],
   "source": [
    "!pip install -c rapidsai -c nvidia -c conda-forge cuml cudatoolkit=11.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cuml'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcuml\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(cuml\u001b[38;5;241m.\u001b[39m__version__)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'cuml'"
     ]
    }
   ],
   "source": [
    "import cuml\n",
    "print(cuml.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting cuml\n",
      "  Downloading cuml-0.6.1.post1.tar.gz (1.1 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Building wheels for collected packages: cuml\n",
      "  Building wheel for cuml (setup.py): started\n",
      "  Building wheel for cuml (setup.py): finished with status 'error'\n",
      "  Running setup.py clean for cuml\n",
      "Failed to build cuml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × python setup.py bdist_wheel did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [47 lines of output]\n",
      "      running bdist_wheel\n",
      "      running build\n",
      "      C:\\Users\\olivi\\anaconda3\\Lib\\site-packages\\setuptools\\_distutils\\cmd.py:66: SetuptoolsDeprecationWarning: setup.py install is deprecated.\n",
      "      !!\n",
      "      \n",
      "              ********************************************************************************\n",
      "              Please avoid running ``setup.py`` directly.\n",
      "              Instead, use pypa/build, pypa/installer or other\n",
      "              standards-based tools.\n",
      "      \n",
      "              See https://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html for details.\n",
      "              ********************************************************************************\n",
      "      \n",
      "      !!\n",
      "        self.initialize_options()\n",
      "      installing to build\\bdist.win-amd64\\wheel\n",
      "      running install\n",
      "      Traceback (most recent call last):\n",
      "        File \"<string>\", line 2, in <module>\n",
      "        File \"<pip-setuptools-caller>\", line 34, in <module>\n",
      "        File \"C:\\Users\\olivi\\AppData\\Local\\Temp\\pip-install-itw20dto\\cuml_3cc929798c234143825c1c4da03755d1\\setup.py\", line 18, in <module>\n",
      "          setup(name=pkg,\n",
      "        File \"C:\\Users\\olivi\\anaconda3\\Lib\\site-packages\\setuptools\\__init__.py\", line 104, in setup\n",
      "          return distutils.core.setup(**attrs)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        File \"C:\\Users\\olivi\\anaconda3\\Lib\\site-packages\\setuptools\\_distutils\\core.py\", line 184, in setup\n",
      "          return run_commands(dist)\n",
      "                 ^^^^^^^^^^^^^^^^^^\n",
      "        File \"C:\\Users\\olivi\\anaconda3\\Lib\\site-packages\\setuptools\\_distutils\\core.py\", line 200, in run_commands\n",
      "          dist.run_commands()\n",
      "        File \"C:\\Users\\olivi\\anaconda3\\Lib\\site-packages\\setuptools\\_distutils\\dist.py\", line 969, in run_commands\n",
      "          self.run_command(cmd)\n",
      "        File \"C:\\Users\\olivi\\anaconda3\\Lib\\site-packages\\setuptools\\dist.py\", line 967, in run_command\n",
      "          super().run_command(command)\n",
      "        File \"C:\\Users\\olivi\\anaconda3\\Lib\\site-packages\\setuptools\\_distutils\\dist.py\", line 988, in run_command\n",
      "          cmd_obj.run()\n",
      "        File \"C:\\Users\\olivi\\anaconda3\\Lib\\site-packages\\wheel\\bdist_wheel.py\", line 403, in run\n",
      "          self.run_command(\"install\")\n",
      "        File \"C:\\Users\\olivi\\anaconda3\\Lib\\site-packages\\setuptools\\_distutils\\cmd.py\", line 316, in run_command\n",
      "          self.distribution.run_command(command)\n",
      "        File \"C:\\Users\\olivi\\anaconda3\\Lib\\site-packages\\setuptools\\dist.py\", line 967, in run_command\n",
      "          super().run_command(command)\n",
      "        File \"C:\\Users\\olivi\\anaconda3\\Lib\\site-packages\\setuptools\\_distutils\\dist.py\", line 988, in run_command\n",
      "          cmd_obj.run()\n",
      "        File \"C:\\Users\\olivi\\AppData\\Local\\Temp\\pip-install-itw20dto\\cuml_3cc929798c234143825c1c4da03755d1\\setup.py\", line 15, in run\n",
      "          raise Exception(long_description)\n",
      "      Exception: Please install cuml via the rapidsai conda channel. See https://rapids.ai/start.html for instructions.\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed building wheel for cuml\n",
      "ERROR: Could not build wheels for cuml, which is required to install pyproject.toml-based projects\n"
     ]
    }
   ],
   "source": [
    "!pip install cuml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
