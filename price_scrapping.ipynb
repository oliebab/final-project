{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"def _scrape_price_stats(url: str) -> dict:\n",
    "    \"\"\"Scrape price statistics using Selenium with cookie banner handling.\"\"\"\n",
    "    chrome_options = Options()\n",
    "    # chrome_options.add_argument(\"--headless\")  # Uncomment for headless mode\n",
    "    chrome_options.add_argument(\"--no-sandbox\")\n",
    "    chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "    chrome_options.add_argument(\"--start-maximized\")\n",
    "    chrome_options.add_argument(\"--disable-notifications\") \n",
    "\n",
    "\n",
    "    try:\n",
    "        driver = webdriver.Chrome(\n",
    "            service=Service(ChromeDriverManager().install()),\n",
    "            options=chrome_options\n",
    "        )\n",
    "        driver.set_page_load_timeout(20)\n",
    "\n",
    "        wait = WebDriverWait(driver, 15)\n",
    "\n",
    "        try:\n",
    "            print(f\"Accessing URL: {url}\")\n",
    "            driver.get(url)\n",
    "\n",
    "            # Wait for page load\n",
    "            print(\"Waiting for page to load...\")\n",
    "            wait.until(EC.presence_of_element_located((By.TAG_NAME, \"body\")))\n",
    "\n",
    "            # Handle cookie banner (if present)\n",
    "            print(\"Checking for cookie banner...\")\n",
    "            try:\n",
    "                cookie_button = wait.until(\n",
    "                    EC.element_to_be_clickable((By.CSS_SELECTOR, \".onetrust-close-btn-handler\"))\n",
    "                )\n",
    "                print(\"Found cookie banner\")\n",
    "                cookie_button.click()\n",
    "                print(\"Accepted cookies\")\n",
    "                time.sleep(1)  # Wait for banner to disappear\n",
    "            except Exception as cookie_error:\n",
    "                print(f\"No cookie banner found or error handling it: {cookie_error}\")\n",
    "\n",
    "            # Add a small delay \n",
    "            time.sleep(2)\n",
    "\n",
    "            print(\"Looking for statistics section...\")\n",
    "            try:\n",
    "                # Find the \"Have\" and \"Want\" buttons and click \"Have\"\n",
    "                have_button = wait.until(\n",
    "                    EC.element_to_be_clickable((By.XPATH, \"//a[contains(text(),'Have')]\"))\n",
    "                )\n",
    "                have_button.click()\n",
    "                time.sleep(2)  # Wait for content to load\n",
    "\n",
    "                # Now find the price elements within the \"Have\" section\n",
    "                price_elements = wait.until(\n",
    "                    EC.presence_of_all_elements_located((By.CSS_SELECTOR, \".community-stats-section dl\"))\n",
    "                )\n",
    "\n",
    "                price_info = {'low': None, 'median': None, 'high': None}\n",
    "\n",
    "                for element in price_elements:\n",
    "                    try:\n",
    "                        label = element.find_element(By.TAG_NAME, \"dt\").text.strip().lower()\n",
    "                        value = element.find_element(By.TAG_NAME, \"dd\").text.strip()\n",
    "                        \n",
    "                        if 'lowest' in label or 'low' in label:\n",
    "                            price_info['low'] = value\n",
    "                        elif 'median' in label:\n",
    "                            price_info['median'] = value\n",
    "                        elif 'highest' in label or 'high' in label:\n",
    "                            price_info['high'] = value\n",
    "\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error extracting price: {e}\")\n",
    "\n",
    "                print(\"Final price information:\", price_info)\n",
    "                return price_info\n",
    "\n",
    "            except Exception as stats_error:\n",
    "                print(f\"Error finding statistics section: {stats_error}\")\n",
    "                return {'low': None, 'median': None, 'high': None}\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error during scraping: {e}\")\n",
    "            return {'low': None, 'median': None, 'high': None}\n",
    "\n",
    "        finally:\n",
    "            print(\"Closing browser...\")\n",
    "            driver.quit()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error initializing Chrome driver: {e}\")\n",
    "        return {'low': None, 'median': None, 'high': None}\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _scrape_price_stats(url: str):\n",
    "        \"\"\"Scrape price statistics from Discogs webpage using Selenium.\"\"\"\n",
    "        # Set Chrome options (you can enable headless mode if desired)\n",
    "        chrome_options = Options()\n",
    "        #chrome_options.add_argument(\"--headless\")\n",
    "        \n",
    "        # Initialize WebDriver using WebDriver Manager\n",
    "        driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)\n",
    "        \n",
    "        try:\n",
    "            # Load the Discogs release page\n",
    "            driver.get(url)\n",
    "            \n",
    "            # Wait for the \"release-stats\" section to load\n",
    "            WebDriverWait(driver, 10).until(\n",
    "                EC.presence_of_element_located((By.ID, \"release-stats\"))\n",
    "            )\n",
    "            \n",
    "            # Locate the price statistics section\n",
    "            price_section = driver.find_element(By.ID, \"release-stats\")\n",
    "\n",
    "            # Initialize a dictionary to store price data\n",
    "            price_info = {'low': None, 'median': None, 'high': None}\n",
    "\n",
    "            # Locate all <li> elements in the price section containing price stats\n",
    "            li_elements = price_section.find_elements(By.TAG_NAME, \"li\")\n",
    "            \n",
    "            for li in li_elements:\n",
    "                # Each <li> should have two spans: one for the label, one for the value\n",
    "                spans = li.find_elements(By.TAG_NAME, \"span\")\n",
    "                if len(spans) == 2:\n",
    "                    label = spans[0].text.strip().lower()\n",
    "                    value = spans[1].text.strip()\n",
    "\n",
    "                    # Map the label to the appropriate field in price_info\n",
    "                    if 'low' in label:\n",
    "                        price_info['low'] = value\n",
    "                    elif 'median' in label:\n",
    "                        price_info['median'] = value\n",
    "                    elif 'high' in label:\n",
    "                        price_info['high'] = value\n",
    "            \n",
    "            return price_info\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error scraping prices with Selenium: {e}\")\n",
    "            return {'low': None, 'median': None, 'high': None}\n",
    "        \n",
    "        finally:\n",
    "            # Close the Selenium driver\n",
    "            driver.quit()\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    url = \"https://www.discogs.com/release/3058849-Floorplan-Sanctified-EP\"\n",
    "    price_data = _scrape_price_stats(url)\n",
    "    print(price_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'low': '€9.70', 'median': '€15.00', 'high': '€26.74'}\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
